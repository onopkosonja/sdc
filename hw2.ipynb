{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "\n",
    "ML разработчикам необходимо не только уметь обучать нейронные сети и генерировать новые идеи, но еще и уметь в страивать наработки в pipeline. В этом домашнем задании нам предстоит сделать из frustum детектора production ready (ну почти) решение, которое может работать на сырых данных.\n",
    "\n",
    "К сожалению, frustum-pointnet работает независимо для каждой 2D детекции. В этом домашнем задании вам предстоит написать обертку над frustum-pointnet, которая будет работать над целыми облаками. Вам также нужно будет воспользоваться 2D детектором, чтобы находить коробки на изображении.\n",
    "\n",
    "Во второй части задания вам нужно будет написать оценку качества работы вашего алгоритма, которая становится чуть сложнее, когда на сцене могут находится много объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1\n",
    "\n",
    "Ниже написан класс, который вам нужно реализовать. Чтобы воспользоваться предобученной сетью, позаимствуйте код из\n",
    "https://github.com/charlesq34/frustum-pointnets/blob/master/train/test.py\n",
    "\n",
    "Предобученные модели лежат здесь: https://shapenet.cs.stanford.edu/media/frustum_pointnets_snapshots.zip\n",
    "\n",
    "В частности, вам нужно модифицировать функцию `get_session_and_ops` - функция должна уметь работать без глобальных флагов. После этого посмотрите, как эта функция используется.\n",
    "Выход сети преобразуется в понятный формат в функции `write_detection_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'posixpath' from '/Applications/anaconda3/lib/python3.7/posixpath.py'>\n"
     ]
    }
   ],
   "source": [
    "# ! pip install \"tensorflow==1.14\"\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "from ssd import SSD\n",
    "sys.path.append(os.path.join(os.getcwd(), 'frustum_pointnets/train'))\n",
    "sys.path.append(os.path.join(os.getcwd(), 'frustum_pointnets/train/test_'))\n",
    "sys.path.append(os.path.join(os.getcwd(), 'frustum_pointnets/kitti'))\n",
    "import provider\n",
    "from test_ import inference, get_session_and_ops\n",
    "from kitti_util import Calibration\n",
    "from kitti_object import get_lidar_in_image_fov, kitti_object\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.affinity import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Detection = namedtuple('Detection', ['xyz', 'angle', 'lwh', 'confidence'])\n",
    "Scene = namedtuple('Scene', ['detections'])\n",
    "\n",
    "class PipelineDetector(object):\n",
    "    def __init__(self, ssd_detector, ssd_threshold, frustum_pointnet, \n",
    "                 frustum_batch_size, frustum_num_pts):\n",
    "        \n",
    "        self.ssd_detector = ssd_detector\n",
    "        self.ssd_threshold = ssd_threshold\n",
    "        \n",
    "        self.frustum_pointnet = frustum_pointnet\n",
    "        self.frustum_batch_size = frustum_batch_size\n",
    "        self.frustum_num_pts = frustum_num_pts\n",
    "        self.frustum_sess, self.frustum_ops = get_session_and_ops(self.frustum_batch_size, self.frustum_num_pts)\n",
    "  \n",
    "    def predict(self, velo_pts, image, calib):\n",
    "        # TODO: run 2D detector on the image\n",
    "        # TODO: extract bounding boxes with vehicle classes and filter them by ssd_threshold\n",
    "        detection = self.ssd_detector.predict(image)\n",
    "        vehicle_idx = np.where(detection['detection_classes'] == 1)\n",
    "        conf_idx = np.where(detection['detection_scores'] >= self.ssd_threshold)\n",
    "        final_idx = np.intersect1d(vehicle_idx, conf_idx)\n",
    "        bbox = detection['detection_boxes'][final_idx]    \n",
    "        detection_conf = detection['detection_scores'][final_idx]\n",
    "\n",
    "        # TODO: process lidar point cloud and construct frustum examples   \n",
    "        rect_pts = np.zeros_like(velo_pts)\n",
    "        rect_pts[:, :3] = calib.project_velo_to_rect(velo_pts[:, :3].copy())\n",
    "        rect_pts[:, 3] = velo_pts[:, 3]\n",
    "        \n",
    "        img_height, img_width, _= image.shape\n",
    "        _, img_pts, in_img_mask = get_lidar_in_image_fov(velo_pts[:, :3].copy(), calib, 0, 0, img_width, img_height, return_more=True)\n",
    "         \n",
    "        frustum_examples = []\n",
    "        frustum_angles = []\n",
    "        scene = Scene([])\n",
    "\n",
    "        for box in bbox:\n",
    "            box = (box.reshape((2, 2)) * image.shape[:2]).astype(int)\n",
    "            (ul_y, ul_x), (lr_y, lr_x)  = box \n",
    "            box_mask = (img_pts[:, 1] < lr_y) * (img_pts[:, 1] >= ul_y) * (img_pts[:, 0] < lr_x) * (img_pts[:, 0] >= ul_x) \n",
    "            \n",
    "            mask = in_img_mask & box_mask\n",
    "            rect_pts_masked = rect_pts[mask]            \n",
    "\n",
    "            if len(rect_pts_masked):\n",
    "                box2d_center = np.array([(ul_x + lr_x) / 2.0, (ul_y + ul_y) / 2.0])\n",
    "                uvdepth = np.zeros((1, 3))\n",
    "                uvdepth[0, :2] = box2d_center\n",
    "                uvdepth[0, 2] = 20 # some random depth\n",
    "                box2d_center_rect = calib.project_image_to_rect(uvdepth)\n",
    "                frustum_angle = -1 * np.arctan2(box2d_center_rect[0, 2], box2d_center_rect[0, 0])\n",
    "                frustum_angle += np.pi/2.0\n",
    "                \n",
    "                np.random.seed()\n",
    "                point_cloud = provider.rotate_pc_along_y(rect_pts_masked.copy(), frustum_angle)\n",
    "                idx = np.random.choice(len(point_cloud), size=self.frustum_num_pts, replace=True)\n",
    "                point_cloud = point_cloud[idx]\n",
    "                \n",
    "                frustum_angles.append(frustum_angle)\n",
    "                frustum_examples.append(point_cloud)\n",
    "            \n",
    "        if len(frustum_examples):\n",
    "            one_hot_batch = np.array([[1, 0, 0],] * len(frustum_examples)).reshape(-1, 3)        \n",
    "\n",
    "            #TODO: run frustum inference (use batch to accelerate inference per frame)\n",
    "            predictions = self.frustum_pointnet(self.frustum_sess, \n",
    "                                               self.frustum_ops, \n",
    "                                               np.array(frustum_examples), \n",
    "                                               one_hot_batch, \n",
    "                                               self.frustum_batch_size)\n",
    "            _, centers, heading_cls, heading_res, size_cls, size_res, _ = predictions\n",
    "\n",
    "            # TODO: construct Scene namedtuple and return it\n",
    "            for i, _ in enumerate(heading_cls):  \n",
    "                h, w, l, tx, ty, tz, ry = provider.from_prediction_to_label_format(centers[i], \n",
    "                                                                                   heading_cls[i], \n",
    "                                                                                   heading_res[i], \n",
    "                                                                                   size_cls[i], \n",
    "                                                                                   size_res[i], \n",
    "                                                                                   frustum_angles[i])\n",
    "                detection = Detection(xyz=np.array((tx, ty, tz)), angle=ry, lwh=np.array((l, w, h)), confidence=detection_conf[i])\n",
    "                scene.detections.append(detection)\n",
    "            return scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2\n",
    "\n",
    "Для оценки качества работы 3D детекторов обычно используется average precision. Как измерить precision и recall детектора?\n",
    "\n",
    "У каждой коробки детектора есть confidence. После того, как мы зафиксировали порог, у нас остается часть детекций.\n",
    "Давайте теперь посмотрим на сцену сверху: bird's eye view. Забудем про координату z.\n",
    "\n",
    "Далее мы можем посчитать IoU между всеми коробками ground truth и нашими детекциями.Давайте решим, что если IoU больше 0.7, то мы будем считать, что мы увидели gt коробку - относим эту детекцию к TP. Если gt не нашла пару - False Negative. Если детекция не нашла пару - False Positive.\n",
    "\n",
    "Ваша задача написать код подсчета метрики average precision построенного детектора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_bbox(labels, calib, types=['Car', 'Van']):\n",
    "    bbox = []\n",
    "    for label in labels:\n",
    "        if label.type in types:\n",
    "            location_ref = np.array(label.t).reshape(1, -1) \n",
    "            location_velo = calib.project_ref_to_velo(location_ref).reshape(-1,)\n",
    "            length = label.l\n",
    "            width = label.w\n",
    "            angle = label.ry\n",
    "            poly = get_polygon(location_velo[:2], width, length, angle)\n",
    "            bbox.append(poly)\n",
    "    filtered_bbox = filter_by_distance(bbox)\n",
    "    return filtered_bbox\n",
    "\n",
    "def get_pred_bbox(detections, calib):\n",
    "    bbox = []\n",
    "    for det in detections:\n",
    "        location_rect = det.xyz.reshape(1, -1)\n",
    "        location_velo =  calib.project_rect_to_velo(location_rect).reshape(-1,)\n",
    "        length, width, _ = det.lwh\n",
    "        angle = det.angle\n",
    "        poly = get_polygon(location_velo[:2], width, length, angle)\n",
    "        bbox.append(poly)\n",
    "    filtered_bbox = filter_by_distance(bbox)\n",
    "    return filtered_bbox\n",
    "            \n",
    "def get_polygon(xy, width, length, angle):\n",
    "    polygon = Polygon([(-width/2, -length/2), (-width/2, length/2), (width/2, length/2), (width/2, -length/2)])\n",
    "    polygon = rotate(polygon, -angle, use_radians=True)\n",
    "    pts = np.array(polygon.exterior.coords)[:4]\n",
    "    pts += xy\n",
    "    return Polygon(pts)\n",
    "\n",
    "def filter_by_distance(bbox, max_dist=40):\n",
    "    centroids = [box.centroid for box in bbox]\n",
    "    dist_bbox = [bbox[i] for (i, c) in enumerate(centroids) if c.x**2 + c.y**2 <= max_dist **2 ]\n",
    "    return dist_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from eval_det.py\n",
    "\n",
    "def compute_iou(polygon1, polygon2):\n",
    "    return polygon1.intersection(polygon2).area / polygon1.union(polygon2).area\n",
    "\n",
    "def voc_ap(rec, prec):\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n",
    "\n",
    "def eval_det_cls(pred, gt, ovthresh=0.7):\n",
    "    \"\"\" Generic functions to compute precision/recall for object detection\n",
    "        for a single class.\n",
    "        Input:\n",
    "            pred: map of {img_id: [(bbox, score)]} where bbox is numpy array\n",
    "            gt: map of {img_id: [bbox]}\n",
    "            ovthresh: scalar, iou threshold\n",
    "        Output:\n",
    "            rec: numpy array of length nd\n",
    "            prec: numpy array of length nd\n",
    "            ap: scalar, average precision\n",
    "    \"\"\"\n",
    "    # construct gt objects\n",
    "    class_recs = {} # {img_id: {'bbox': bbox list, 'det': matched list}}\n",
    "    npos = 0\n",
    "    for img_id in gt.keys():\n",
    "        bbox = np.array(gt[img_id])\n",
    "        det = [False] * len(bbox)\n",
    "        npos += len(bbox)\n",
    "        class_recs[img_id] = {'bbox': bbox, 'det': det}\n",
    "    # pad empty list to all other imgids\n",
    "    for img_id in pred.keys():\n",
    "        if img_id not in gt:\n",
    "            class_recs[img_id] = {'bbox': np.array([]), 'det': []}\n",
    "\n",
    "    # construct dets\n",
    "    image_ids = []\n",
    "    confidence = []\n",
    "    BB = []\n",
    "    for img_id in pred.keys():\n",
    "        for box,score in pred[img_id]:\n",
    "            image_ids.append(img_id)\n",
    "            confidence.append(score)\n",
    "            BB.append(box)\n",
    "    confidence = np.array(confidence)\n",
    "    BB = np.array(BB) # (nd,4 or 8,3)\n",
    "\n",
    "    # sort by confidence\n",
    "    sorted_ind = np.argsort(-confidence)\n",
    "    sorted_scores = np.sort(-confidence)\n",
    "    BB = BB[sorted_ind]\n",
    "    image_ids = [image_ids[x] for x in sorted_ind]\n",
    "\n",
    "    # go down dets and mark TPs and FPs\n",
    "    nd = len(image_ids)\n",
    "    tp = np.zeros(nd)\n",
    "    fp = np.zeros(nd)\n",
    "    for d in range(nd):\n",
    "        R = class_recs[image_ids[d]]\n",
    "        bb = BB[d]\n",
    "        ovmax = -np.inf\n",
    "        BBGT = R['bbox']\n",
    "\n",
    "        if BBGT.size > 0:\n",
    "            # compute overlaps\n",
    "            for j in range(BBGT.shape[0]):\n",
    "                iou = compute_iou(bb, BBGT[j]) \n",
    "                if iou > ovmax:\n",
    "                    ovmax = iou\n",
    "                    jmax = j\n",
    "\n",
    "        #print d, ovmax\n",
    "        if ovmax > ovthresh:\n",
    "            if not R['det'][jmax]:\n",
    "                tp[d] = 1.\n",
    "                R['det'][jmax] = 1\n",
    "            else:\n",
    "                fp[d] = 1.\n",
    "        else:\n",
    "            fp[d] = 1.\n",
    "\n",
    "    # compute precision recall\n",
    "    fp = np.cumsum(fp)\n",
    "    tp = np.cumsum(tp)\n",
    "    rec = tp / float(npos)\n",
    "    # avoid divide by zero in case the first detection matches a difficult\n",
    "    # ground truth\n",
    "    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "    ap = voc_ap(rec, prec)\n",
    "\n",
    "    return rec, prec, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detections_and_gt(dataset_len):\n",
    "    ssd = SSD()\n",
    "    detector = PipelineDetector(ssd_detector=ssd, \n",
    "                                ssd_threshold=0.5, \n",
    "                                frustum_pointnet=inference, \n",
    "                                frustum_batch_size=1, \n",
    "                                frustum_num_pts=1024)\n",
    "    dataset = kitti_object(root_dir='./')\n",
    "    \n",
    "    det_bboxs = dict()\n",
    "    gt_bboxs = dict()\n",
    "    \n",
    "    for idx in tqdm(range(dataset_len)):\n",
    "        img = dataset.get_image(idx)\n",
    "        lidar = dataset.get_lidar(idx)\n",
    "        calib = dataset.get_calibration(idx)\n",
    "        labels = dataset.get_label_objects(idx)\n",
    "        scene = detector.predict(lidar, img, calib)\n",
    "        \n",
    "        if scene is not None:       \n",
    "            det_bbox = get_pred_bbox(scene.detections, calib)\n",
    "            gt_bbox = get_gt_bbox(labels, calib)\n",
    "\n",
    "            box_with_conf = []\n",
    "            for i, box in enumerate(det_bbox):\n",
    "                conf = scene.detections[i].confidence\n",
    "                box_with_conf.append([box, conf])\n",
    "            det_bboxs[idx] = box_with_conf \n",
    "            gt_bboxs[idx] = gt_bbox\n",
    "    return det_bboxs, gt_bboxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/ssd.py:91: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/ssd.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/models/model_util.py:175: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/models/tf_util.py:155: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/models/tf_util.py:21: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/models/tf_util.py:384: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/models/tf_util.py:613: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/models/model_util.py:211: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/models/model_util.py:212: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/models/model_util.py:64: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/models/model_util.py:302: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "INFO:tensorflow:Summary name 3d mask loss is illegal; using 3d_mask_loss instead.\n",
      "INFO:tensorflow:Summary name center loss is illegal; using center_loss instead.\n",
      "INFO:tensorflow:Summary name stage1 center loss is illegal; using stage1_center_loss instead.\n",
      "INFO:tensorflow:Summary name heading class loss is illegal; using heading_class_loss instead.\n",
      "INFO:tensorflow:Summary name heading residual normalized loss is illegal; using heading_residual_normalized_loss instead.\n",
      "INFO:tensorflow:Summary name size class loss is illegal; using size_class_loss instead.\n",
      "INFO:tensorflow:Summary name size residual normalized loss is illegal; using size_residual_normalized_loss instead.\n",
      "INFO:tensorflow:Summary name corners loss is illegal; using corners_loss instead.\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/models/model_util.py:396: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/train/test_.py:69: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/train/test_.py:72: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/frustum_pointnets/train/test_.py:75: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /Users/sofia/Desktop/frustum/frustum_pointnets/train/log_v1/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sofia/Desktop/frustum/ssd.py:23: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 86/1000 [20:47<3:33:21, 14.01s/it]/Users/sofia/Desktop/frustum/frustum_pointnets/train/test_.py:139: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mask_mean_prob = mask_mean_prob / np.sum(batch_seg_mask,1) # B,\n",
      "100%|██████████| 1000/1000 [4:07:13<00:00, 14.83s/it] \n"
     ]
    }
   ],
   "source": [
    "dataset_len = len(glob.glob(os.path.join('training/calib', '*txt')))\n",
    "det_bboxs, gt_bboxs = get_detections_and_gt(dataset_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, ap = eval_det_cls(det_bboxs, gt_bboxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.526671479119225"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
